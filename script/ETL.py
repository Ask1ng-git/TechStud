from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import seaborn as sns
import missingno as mno
import matplotlib.pyplot as plt
import os

def etl_process(csv_file, output_dir="./CSV"):
    try:
        df = pd.read_csv(csv_file, encoding='ISO-8859-1')
        print(f"Fichier {csv_file} charg√© avec succ√®s !")

        # V√©rifier les noms des colonnes et les corriger si n√©cessaire
        print("Noms des colonnes dans le fichier CSV avant correction :")
        print(list(df.columns))

        if "Lat" in df.columns and "Long" in df.columns:
            df.drop(columns=["Lat", "Long"], inplace=True)
            print("Suppression des colonnes 'Lat' et 'Long' effectu√©e.")
        else:
            print("Attention : Les colonnes 'Lat' et 'Long' n'existent pas dans le fichier CSV.")

        # Aper√ßu des 10 premi√®res et 10 derni√®res lignes
        print("Aper√ßu des 10 premi√®res lignes des donn√©es :")
        print(df.head(10))

        print("Aper√ßu des 10 derni√®res lignes des donn√©es :")
        print(df.tail(10))

        # Description statistique
        print("\nüîç Description statistique :")
        print(df.describe())

        # GESTION DES DONN√âES MANQUANTES
        print("Gestion des valeurs manquantes...")

        # Calcul du nombre et du pourcentage de valeurs manquantes avant traitement
        missing_before = df.isnull().sum()
        missing_percent = (df.isnull().sum() * 100 / len(df)).round(2)  # Pourcentage arrondi √† 2 d√©cimales

        # Affichage d√©taill√© des valeurs manquantes
        missing_data = pd.DataFrame({"Valeurs Manquantes": missing_before, "Pourcentage (%)": missing_percent})
        print("D√©tails des valeurs manquantes AVANT traitement :")
        print(missing_data[missing_data["Valeurs Manquantes"] > 0])  # On n'affiche que les colonnes ayant des valeurs manquantes

        # Visualisation des valeurs manquantes AVANT traitement
        print("Visualisation des valeurs manquantes AVANT traitement...")
        mno.matrix(df, figsize=(12, 6))
        plt.title("Visualisation des valeurs manquantes AVANT traitement")
        plt.show()

        # Gestion des valeurs manquantes
        df.fillna(0, inplace=True)

        # V√©rification et recalcul correct de Active
        if all(col in df.columns for col in ["Confirmed", "Deaths", "Recovered"]):
            df["Active"] = df["Confirmed"] - df["Deaths"] - df["Recovered"]
            print("Recalcul de 'Active' effectu√© avec succ√®s.")
        else:
            print("\Attention : Certaines colonnes n√©cessaires au recalcul de 'Active' sont absentes.")

        # Gestion des doublons
        print("Suppression des doublons...")
        before_dedup = df.shape[0]
        df.drop_duplicates(inplace=True)
        after_dedup = df.shape[0]
        print(f" {before_dedup - after_dedup} doublon(s) supprim√©(s).")

        # V√©rification des valeurs manquantes apr√®s traitement
        print("Visualisation des valeurs manquantes APR√àS traitement...")
        mno.matrix(df, figsize=(12, 6))
        plt.title("Visualisation des valeurs manquantes APR√àS traitement")
        plt.show()

        # ‚úÖ D√©tection des valeurs aberrantes
        print(" D√©tection des valeurs aberrantes...")
        if "Confirmed" in df.columns:
            outliers = df[df["Confirmed"] > df["Confirmed"].quantile(0.99)]
            print(f"‚ö†Ô∏è {len(outliers)} valeurs aberrantes d√©tect√©es.")

            #Affichage des valeurs aberrantes d√©tect√©es (optionnel)
            if not outliers.empty:
                print("Aper√ßu des valeurs aberrantes d√©tect√©es :")
                print(outliers[["Country/Region", "Confirmed", "Deaths", "Recovered", "Active"]].head(10))  # Affiche 10 valeurs aberrantes
        else:
            print("Attention : La colonne 'Confirmed' est absente, impossible de d√©tecter les valeurs aberrantes.")

        # Validation des donn√©es (v√©rification des anomalies)
        print("\ Validation des donn√©es : V√©rification de la coh√©rence")
        if all(col in df.columns for col in ["Confirmed", "Deaths", "Recovered", "Active"]):
            df["TrueConfirmed"] = df["Deaths"] + df["Recovered"] + df["Active"]
            df["Anomaly"] = df["Confirmed"] != df["TrueConfirmed"]

            anomalies = df[df["Anomaly"]]
            if not anomalies.empty:
                print("Anomalies d√©tect√©es :")
                print(anomalies[["Confirmed", "Deaths", "Recovered", "Active", "TrueConfirmed"]])
            else:
                print("Aucune anomalie d√©tect√©e.")
        else:
            print("ERREUR : Impossible de valider la coh√©rence des donn√©es, certaines colonnes sont absentes.")

        # Affichage de la matrice de corr√©lation AVANT le d√©coupage
        print("Analyse visuelle : Matrice de corr√©lation")
        numeric_df = df.select_dtypes(include=["number"])
        if not numeric_df.empty:
            plt.figure(figsize=(10, 8))
            sns.heatmap(numeric_df.corr(), annot=True, cmap="Blues")
            plt.title("Matrice de corr√©lation")
            plt.show()
        else:
            print("Aucune donn√©e num√©rique disponible pour afficher une matrice de corr√©lation.")

        # ‚úÖ D√©coupage Train-Test-Validation
        train, test, validation = split_data(df, output_dir)

        return train, test, validation

    except FileNotFoundError:
        print(f"‚ùå Erreur : Fichier {csv_file} introuvable !")
        return None, None, None  # Evite un crash en cas de fichier manquant

    except Exception as e:
        print(f"‚ùå Erreur inattendue : {e}")
        return None, None, None  # Evite un crash si une erreur se produit



def split_data(df, output_dir="./CSV"):
    """
    S√©pare les donn√©es en ensembles d'entra√Ænement, test et validation.
    Effectue des v√©rifications sur la taille et l'unicit√© des donn√©es.
    Enregistre chaque ensemble sous forme de fichier CSV.
    """
    # D√©coupage Train-Test-Validation
    train, temp = train_test_split(df, test_size=0.3, random_state=42)
    test, validation = train_test_split(temp, test_size=0.33, random_state=42)  # 20% test, 10% validation

    #  Affichage des dimensions des datasets
    print("Dimensions des ensembles :")
    print(f"Train : {train.shape}, Test : {test.shape}, Validation : {validation.shape}")

    #  Validation des proportions et des doublons
    validate_splits(train, test, validation)

    # Sauvegarde des fichiers
    os.makedirs(output_dir, exist_ok=True)
    train.to_csv(f"{output_dir}/train.csv", index=False)
    test.to_csv(f"{output_dir}/test.csv", index=False)
    validation.to_csv(f"{output_dir}/validation.csv", index=False)

    print(f"Donn√©es divis√©es et sauvegard√©es dans {output_dir} (Train: {len(train)}, Test: {len(test)}, Validation: {len(validation)})")

    return train, test, validation



def validate_splits(train, test, validation):
    """
    V√©rifie la r√©partition et l'unicit√© des ensembles Train-Test-Validation.
    """
    print("V√©rification des proportions :")
    total_size = len(train) + len(test) + len(validation)
    
    print(f"Taille totale des donn√©es : {total_size}")
    print(f"Taille Train : {len(train)} ({round(len(train) / total_size * 100, 2)}%)")
    print(f"Taille Test : {len(test)} ({round(len(test) / total_size * 100, 2)}%)")
    print(f"Taille Validation : {len(validation)} ({round(len(validation) / total_size * 100, 2)}%)")



# üèÅ Ex√©cution du pipeline ETL
cleaned_df = etl_process("./CSV/covid_19_clean_complete.csv")
